2020-11-25 14:34:43 [scrapy.utils.log] INFO: Scrapy 2.3.0 started (bot: ranking)
2020-11-25 14:34:43 [scrapy.utils.log] INFO: Versions: lxml 4.5.2.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.7.6 (tags/v3.7.6:43364a7ae0, Dec 19 2019, 00:42:30) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1h  22 Sep 2020), cryptography 3.1.1, Platform Windows-10-10.0.17763-SP0
2020-11-25 14:34:43 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-11-25 14:34:43 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ranking',
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'ranking.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ranking.spiders']}
2020-11-25 14:34:43 [scrapy.extensions.telnet] INFO: Telnet Password: cd631758b567bbd3
2020-11-25 14:34:43 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-11-25 14:34:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-11-25 14:34:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-11-25 14:34:44 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-11-25 14:34:44 [scrapy.core.engine] INFO: Spider opened
2020-11-25 14:34:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-11-25 14:34:44 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-11-25 14:34:44 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.shanghairanking.cn/robots.txt> (referer: None)
2020-11-25 14:34:44 [protego] DEBUG: Rule at line 4 without any user agent to enforce it on.
2020-11-25 14:34:44 [protego] DEBUG: Rule at line 7 without any user agent to enforce it on.
2020-11-25 14:34:44 [protego] DEBUG: Rule at line 9 without any user agent to enforce it on.
2020-11-25 14:34:44 [protego] DEBUG: Rule at line 11 without any user agent to enforce it on.
2020-11-25 14:34:44 [protego] DEBUG: Rule at line 13 without any user agent to enforce it on.
2020-11-25 14:34:44 [protego] DEBUG: Rule at line 15 without any user agent to enforce it on.
2020-11-25 14:34:44 [protego] DEBUG: Rule at line 17 without any user agent to enforce it on.
2020-11-25 14:34:44 [protego] DEBUG: Rule at line 19 without any user agent to enforce it on.
2020-11-25 14:34:44 [protego] DEBUG: Rule at line 21 without any user agent to enforce it on.
2020-11-25 14:34:44 [protego] DEBUG: Rule at line 23 without any user agent to enforce it on.
2020-11-25 14:34:44 [protego] DEBUG: Rule at line 24 without any user agent to enforce it on.
2020-11-25 14:34:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.shanghairanking.cn/rankings/bcur/2020> (referer: None)
2020-11-25 14:34:45 [scrapy.core.engine] INFO: Closing spider (finished)
2020-11-25 14:34:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 472,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 33141,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/404': 1,
 'elapsed_time_seconds': 1.673369,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 11, 25, 6, 34, 45, 819692),
 'log_count/DEBUG': 13,
 'log_count/INFO': 10,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2020, 11, 25, 6, 34, 44, 146323)}
2020-11-25 14:34:45 [scrapy.core.engine] INFO: Spider closed (finished)
2020-11-25 14:35:34 [scrapy.utils.log] INFO: Scrapy 2.3.0 started (bot: ranking)
2020-11-25 14:35:34 [scrapy.utils.log] INFO: Versions: lxml 4.5.2.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.7.6 (tags/v3.7.6:43364a7ae0, Dec 19 2019, 00:42:30) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1h  22 Sep 2020), cryptography 3.1.1, Platform Windows-10-10.0.17763-SP0
2020-11-25 14:35:34 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-11-25 14:35:34 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ranking',
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'ranking.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ranking.spiders']}
2020-11-25 14:35:34 [scrapy.extensions.telnet] INFO: Telnet Password: 866d3b35a9725d6e
2020-11-25 14:35:34 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-11-25 14:35:34 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-11-25 14:35:34 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-11-25 14:35:34 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-11-25 14:35:34 [scrapy.core.engine] INFO: Spider opened
2020-11-25 14:35:35 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-11-25 14:35:35 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-11-25 14:35:35 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.shanghairanking.cn/robots.txt> (referer: None)
2020-11-25 14:35:35 [protego] DEBUG: Rule at line 4 without any user agent to enforce it on.
2020-11-25 14:35:35 [protego] DEBUG: Rule at line 7 without any user agent to enforce it on.
2020-11-25 14:35:35 [protego] DEBUG: Rule at line 9 without any user agent to enforce it on.
2020-11-25 14:35:35 [protego] DEBUG: Rule at line 11 without any user agent to enforce it on.
2020-11-25 14:35:35 [protego] DEBUG: Rule at line 13 without any user agent to enforce it on.
2020-11-25 14:35:35 [protego] DEBUG: Rule at line 15 without any user agent to enforce it on.
2020-11-25 14:35:35 [protego] DEBUG: Rule at line 17 without any user agent to enforce it on.
2020-11-25 14:35:35 [protego] DEBUG: Rule at line 19 without any user agent to enforce it on.
2020-11-25 14:35:35 [protego] DEBUG: Rule at line 21 without any user agent to enforce it on.
2020-11-25 14:35:35 [protego] DEBUG: Rule at line 23 without any user agent to enforce it on.
2020-11-25 14:35:35 [protego] DEBUG: Rule at line 24 without any user agent to enforce it on.
2020-11-25 14:35:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.shanghairanking.cn/rankings/bcur/2020> (referer: None)
2020-11-25 14:35:37 [scrapy.core.engine] INFO: Closing spider (finished)
2020-11-25 14:35:37 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 472,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 33141,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/404': 1,
 'elapsed_time_seconds': 2.365094,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 11, 25, 6, 35, 37, 367127),
 'log_count/DEBUG': 13,
 'log_count/INFO': 10,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2020, 11, 25, 6, 35, 35, 2033)}
2020-11-25 14:35:37 [scrapy.core.engine] INFO: Spider closed (finished)
2020-11-25 14:35:59 [scrapy.utils.log] INFO: Scrapy 2.3.0 started (bot: ranking)
2020-11-25 14:35:59 [scrapy.utils.log] INFO: Versions: lxml 4.5.2.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.7.6 (tags/v3.7.6:43364a7ae0, Dec 19 2019, 00:42:30) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1h  22 Sep 2020), cryptography 3.1.1, Platform Windows-10-10.0.17763-SP0
2020-11-25 14:35:59 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-11-25 14:35:59 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ranking',
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'ranking.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ranking.spiders']}
2020-11-25 14:35:59 [scrapy.extensions.telnet] INFO: Telnet Password: 781da36561b384d8
2020-11-25 14:35:59 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-11-25 14:36:00 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-11-25 14:36:00 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-11-25 14:36:00 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-11-25 14:36:00 [scrapy.core.engine] INFO: Spider opened
2020-11-25 14:36:00 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-11-25 14:36:00 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-11-25 14:36:00 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.shanghairanking.cn/robots.txt> (referer: None)
2020-11-25 14:36:00 [protego] DEBUG: Rule at line 4 without any user agent to enforce it on.
2020-11-25 14:36:00 [protego] DEBUG: Rule at line 7 without any user agent to enforce it on.
2020-11-25 14:36:00 [protego] DEBUG: Rule at line 9 without any user agent to enforce it on.
2020-11-25 14:36:00 [protego] DEBUG: Rule at line 11 without any user agent to enforce it on.
2020-11-25 14:36:00 [protego] DEBUG: Rule at line 13 without any user agent to enforce it on.
2020-11-25 14:36:00 [protego] DEBUG: Rule at line 15 without any user agent to enforce it on.
2020-11-25 14:36:00 [protego] DEBUG: Rule at line 17 without any user agent to enforce it on.
2020-11-25 14:36:00 [protego] DEBUG: Rule at line 19 without any user agent to enforce it on.
2020-11-25 14:36:00 [protego] DEBUG: Rule at line 21 without any user agent to enforce it on.
2020-11-25 14:36:00 [protego] DEBUG: Rule at line 23 without any user agent to enforce it on.
2020-11-25 14:36:00 [protego] DEBUG: Rule at line 24 without any user agent to enforce it on.
2020-11-25 14:36:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.shanghairanking.cn/rankings/bcur/2020> (referer: None)
2020-11-25 14:36:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.shanghairanking.cn/rankings/bcur/2020> (referer: None)
Traceback (most recent call last):
  File "c:\users\user\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\user\Documents\Course\爬虫\Web-Crawler\Object6\ranking\ranking\spiders\getRanking.py", line 28, in parse
    print(info.text)
  File "c:\users\user\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 923, in __getattr__
    self.__class__.__name__, attr))
AttributeError: 'NavigableString' object has no attribute 'text'
2020-11-25 14:36:01 [scrapy.core.engine] INFO: Closing spider (finished)
2020-11-25 14:36:01 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 472,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 33141,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/404': 1,
 'elapsed_time_seconds': 1.666073,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 11, 25, 6, 36, 1, 776643),
 'log_count/DEBUG': 13,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2020, 11, 25, 6, 36, 0, 110570)}
2020-11-25 14:36:01 [scrapy.core.engine] INFO: Spider closed (finished)
2020-11-25 14:37:26 [scrapy.utils.log] INFO: Scrapy 2.3.0 started (bot: ranking)
2020-11-25 14:37:26 [scrapy.utils.log] INFO: Versions: lxml 4.5.2.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.7.6 (tags/v3.7.6:43364a7ae0, Dec 19 2019, 00:42:30) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1h  22 Sep 2020), cryptography 3.1.1, Platform Windows-10-10.0.17763-SP0
2020-11-25 14:37:26 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-11-25 14:37:26 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ranking',
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'ranking.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ranking.spiders']}
2020-11-25 14:37:26 [scrapy.extensions.telnet] INFO: Telnet Password: c946f4a3fcf1ea2f
2020-11-25 14:37:26 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-11-25 14:37:26 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-11-25 14:37:26 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-11-25 14:37:26 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-11-25 14:37:26 [scrapy.core.engine] INFO: Spider opened
2020-11-25 14:37:26 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-11-25 14:37:26 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-11-25 14:37:27 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.shanghairanking.cn/robots.txt> (referer: None)
2020-11-25 14:37:27 [protego] DEBUG: Rule at line 4 without any user agent to enforce it on.
2020-11-25 14:37:27 [protego] DEBUG: Rule at line 7 without any user agent to enforce it on.
2020-11-25 14:37:27 [protego] DEBUG: Rule at line 9 without any user agent to enforce it on.
2020-11-25 14:37:27 [protego] DEBUG: Rule at line 11 without any user agent to enforce it on.
2020-11-25 14:37:27 [protego] DEBUG: Rule at line 13 without any user agent to enforce it on.
2020-11-25 14:37:27 [protego] DEBUG: Rule at line 15 without any user agent to enforce it on.
2020-11-25 14:37:27 [protego] DEBUG: Rule at line 17 without any user agent to enforce it on.
2020-11-25 14:37:27 [protego] DEBUG: Rule at line 19 without any user agent to enforce it on.
2020-11-25 14:37:27 [protego] DEBUG: Rule at line 21 without any user agent to enforce it on.
2020-11-25 14:37:27 [protego] DEBUG: Rule at line 23 without any user agent to enforce it on.
2020-11-25 14:37:27 [protego] DEBUG: Rule at line 24 without any user agent to enforce it on.
2020-11-25 14:37:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.shanghairanking.cn/rankings/bcur/2020> (referer: None)
2020-11-25 14:37:29 [scrapy.core.engine] INFO: Closing spider (finished)
2020-11-25 14:37:29 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 472,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 33141,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/404': 1,
 'elapsed_time_seconds': 2.342062,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 11, 25, 6, 37, 29, 166401),
 'log_count/DEBUG': 13,
 'log_count/INFO': 10,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2020, 11, 25, 6, 37, 26, 824339)}
2020-11-25 14:37:29 [scrapy.core.engine] INFO: Spider closed (finished)
2020-11-25 14:40:49 [scrapy.utils.log] INFO: Scrapy 2.3.0 started (bot: ranking)
2020-11-25 14:40:49 [scrapy.utils.log] INFO: Versions: lxml 4.5.2.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.7.6 (tags/v3.7.6:43364a7ae0, Dec 19 2019, 00:42:30) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1h  22 Sep 2020), cryptography 3.1.1, Platform Windows-10-10.0.17763-SP0
2020-11-25 14:40:49 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-11-25 14:40:49 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ranking',
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'ranking.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ranking.spiders']}
2020-11-25 14:40:49 [scrapy.extensions.telnet] INFO: Telnet Password: 2c74f98056bad1ed
2020-11-25 14:40:50 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-11-25 14:40:50 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-11-25 14:40:50 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-11-25 14:40:50 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-11-25 14:40:50 [scrapy.core.engine] INFO: Spider opened
2020-11-25 14:40:50 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-11-25 14:40:50 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-11-25 14:40:50 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.shanghairanking.cn/robots.txt> (referer: None)
2020-11-25 14:40:50 [protego] DEBUG: Rule at line 4 without any user agent to enforce it on.
2020-11-25 14:40:50 [protego] DEBUG: Rule at line 7 without any user agent to enforce it on.
2020-11-25 14:40:50 [protego] DEBUG: Rule at line 9 without any user agent to enforce it on.
2020-11-25 14:40:50 [protego] DEBUG: Rule at line 11 without any user agent to enforce it on.
2020-11-25 14:40:50 [protego] DEBUG: Rule at line 13 without any user agent to enforce it on.
2020-11-25 14:40:50 [protego] DEBUG: Rule at line 15 without any user agent to enforce it on.
2020-11-25 14:40:50 [protego] DEBUG: Rule at line 17 without any user agent to enforce it on.
2020-11-25 14:40:50 [protego] DEBUG: Rule at line 19 without any user agent to enforce it on.
2020-11-25 14:40:50 [protego] DEBUG: Rule at line 21 without any user agent to enforce it on.
2020-11-25 14:40:50 [protego] DEBUG: Rule at line 23 without any user agent to enforce it on.
2020-11-25 14:40:50 [protego] DEBUG: Rule at line 24 without any user agent to enforce it on.
2020-11-25 14:40:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.shanghairanking.cn/rankings/bcur/2020> (referer: None)
2020-11-25 14:40:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.shanghairanking.cn/rankings/bcur/2020> (referer: None)
Traceback (most recent call last):
  File "c:\users\user\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\user\Documents\Course\爬虫\Web-Crawler\Object6\ranking\ranking\spiders\getRanking.py", line 29, in parse
    name = info.select("a").text
  File "c:\users\user\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 2166, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'text'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?
2020-11-25 14:40:52 [scrapy.core.engine] INFO: Closing spider (finished)
2020-11-25 14:40:52 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 472,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 33141,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/404': 1,
 'elapsed_time_seconds': 1.824815,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 11, 25, 6, 40, 52, 100946),
 'log_count/DEBUG': 13,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2020, 11, 25, 6, 40, 50, 276131)}
2020-11-25 14:40:52 [scrapy.core.engine] INFO: Spider closed (finished)
2020-11-25 14:41:02 [scrapy.utils.log] INFO: Scrapy 2.3.0 started (bot: ranking)
2020-11-25 14:41:02 [scrapy.utils.log] INFO: Versions: lxml 4.5.2.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.7.6 (tags/v3.7.6:43364a7ae0, Dec 19 2019, 00:42:30) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1h  22 Sep 2020), cryptography 3.1.1, Platform Windows-10-10.0.17763-SP0
2020-11-25 14:41:02 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-11-25 14:41:02 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ranking',
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'ranking.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ranking.spiders']}
2020-11-25 14:41:02 [scrapy.extensions.telnet] INFO: Telnet Password: 09e7e3940bcd00ed
2020-11-25 14:41:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-11-25 14:41:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-11-25 14:41:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-11-25 14:41:02 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-11-25 14:41:02 [scrapy.core.engine] INFO: Spider opened
2020-11-25 14:41:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-11-25 14:41:02 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-11-25 14:41:03 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.shanghairanking.cn/robots.txt> (referer: None)
2020-11-25 14:41:03 [protego] DEBUG: Rule at line 4 without any user agent to enforce it on.
2020-11-25 14:41:03 [protego] DEBUG: Rule at line 7 without any user agent to enforce it on.
2020-11-25 14:41:03 [protego] DEBUG: Rule at line 9 without any user agent to enforce it on.
2020-11-25 14:41:03 [protego] DEBUG: Rule at line 11 without any user agent to enforce it on.
2020-11-25 14:41:03 [protego] DEBUG: Rule at line 13 without any user agent to enforce it on.
2020-11-25 14:41:03 [protego] DEBUG: Rule at line 15 without any user agent to enforce it on.
2020-11-25 14:41:03 [protego] DEBUG: Rule at line 17 without any user agent to enforce it on.
2020-11-25 14:41:03 [protego] DEBUG: Rule at line 19 without any user agent to enforce it on.
2020-11-25 14:41:03 [protego] DEBUG: Rule at line 21 without any user agent to enforce it on.
2020-11-25 14:41:03 [protego] DEBUG: Rule at line 23 without any user agent to enforce it on.
2020-11-25 14:41:03 [protego] DEBUG: Rule at line 24 without any user agent to enforce it on.
2020-11-25 14:41:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.shanghairanking.cn/rankings/bcur/2020> (referer: None)
2020-11-25 14:41:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.shanghairanking.cn/rankings/bcur/2020> (referer: None)
Traceback (most recent call last):
  File "c:\users\user\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\user\Documents\Course\爬虫\Web-Crawler\Object6\ranking\ranking\spiders\getRanking.py", line 29, in parse
    name = info.select("a").text
  File "c:\users\user\appdata\local\programs\python\python37\lib\site-packages\bs4\element.py", line 2166, in __getattr__
    "ResultSet object has no attribute '%s'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?" % key
AttributeError: ResultSet object has no attribute 'text'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?
2020-11-25 14:41:04 [scrapy.core.engine] INFO: Closing spider (finished)
2020-11-25 14:41:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 472,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 33141,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/404': 1,
 'elapsed_time_seconds': 1.841325,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 11, 25, 6, 41, 4, 534161),
 'log_count/DEBUG': 13,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2020, 11, 25, 6, 41, 2, 692836)}
2020-11-25 14:41:04 [scrapy.core.engine] INFO: Spider closed (finished)
2020-11-25 14:41:53 [scrapy.utils.log] INFO: Scrapy 2.3.0 started (bot: ranking)
2020-11-25 14:41:53 [scrapy.utils.log] INFO: Versions: lxml 4.5.2.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.7.6 (tags/v3.7.6:43364a7ae0, Dec 19 2019, 00:42:30) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1h  22 Sep 2020), cryptography 3.1.1, Platform Windows-10-10.0.17763-SP0
2020-11-25 14:41:53 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-11-25 14:41:53 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ranking',
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'ranking.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ranking.spiders']}
2020-11-25 14:41:53 [scrapy.extensions.telnet] INFO: Telnet Password: 9b01f5cd801fb010
2020-11-25 14:41:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-11-25 14:41:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-11-25 14:41:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-11-25 14:41:53 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-11-25 14:41:53 [scrapy.core.engine] INFO: Spider opened
2020-11-25 14:41:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-11-25 14:41:53 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-11-25 14:41:53 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.shanghairanking.cn/robots.txt> (referer: None)
2020-11-25 14:41:53 [protego] DEBUG: Rule at line 4 without any user agent to enforce it on.
2020-11-25 14:41:53 [protego] DEBUG: Rule at line 7 without any user agent to enforce it on.
2020-11-25 14:41:53 [protego] DEBUG: Rule at line 9 without any user agent to enforce it on.
2020-11-25 14:41:53 [protego] DEBUG: Rule at line 11 without any user agent to enforce it on.
2020-11-25 14:41:53 [protego] DEBUG: Rule at line 13 without any user agent to enforce it on.
2020-11-25 14:41:53 [protego] DEBUG: Rule at line 15 without any user agent to enforce it on.
2020-11-25 14:41:53 [protego] DEBUG: Rule at line 17 without any user agent to enforce it on.
2020-11-25 14:41:53 [protego] DEBUG: Rule at line 19 without any user agent to enforce it on.
2020-11-25 14:41:53 [protego] DEBUG: Rule at line 21 without any user agent to enforce it on.
2020-11-25 14:41:53 [protego] DEBUG: Rule at line 23 without any user agent to enforce it on.
2020-11-25 14:41:53 [protego] DEBUG: Rule at line 24 without any user agent to enforce it on.
2020-11-25 14:41:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.shanghairanking.cn/rankings/bcur/2020> (referer: None)
2020-11-25 14:41:55 [scrapy.core.engine] INFO: Closing spider (finished)
2020-11-25 14:41:55 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 472,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 33141,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/404': 1,
 'elapsed_time_seconds': 1.90842,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 11, 25, 6, 41, 55, 514574),
 'log_count/DEBUG': 13,
 'log_count/INFO': 10,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2020, 11, 25, 6, 41, 53, 606154)}
2020-11-25 14:41:55 [scrapy.core.engine] INFO: Spider closed (finished)
2020-11-25 14:42:14 [scrapy.utils.log] INFO: Scrapy 2.3.0 started (bot: ranking)
2020-11-25 14:42:14 [scrapy.utils.log] INFO: Versions: lxml 4.5.2.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.7.6 (tags/v3.7.6:43364a7ae0, Dec 19 2019, 00:42:30) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1h  22 Sep 2020), cryptography 3.1.1, Platform Windows-10-10.0.17763-SP0
2020-11-25 14:42:14 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-11-25 14:42:14 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ranking',
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'ranking.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ranking.spiders']}
2020-11-25 14:42:14 [scrapy.extensions.telnet] INFO: Telnet Password: 2448f955cb5bed71
2020-11-25 14:42:14 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-11-25 14:42:14 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-11-25 14:42:14 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-11-25 14:42:14 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-11-25 14:42:14 [scrapy.core.engine] INFO: Spider opened
2020-11-25 14:42:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-11-25 14:42:14 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-11-25 14:42:14 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.shanghairanking.cn/robots.txt> (referer: None)
2020-11-25 14:42:14 [protego] DEBUG: Rule at line 4 without any user agent to enforce it on.
2020-11-25 14:42:14 [protego] DEBUG: Rule at line 7 without any user agent to enforce it on.
2020-11-25 14:42:14 [protego] DEBUG: Rule at line 9 without any user agent to enforce it on.
2020-11-25 14:42:14 [protego] DEBUG: Rule at line 11 without any user agent to enforce it on.
2020-11-25 14:42:14 [protego] DEBUG: Rule at line 13 without any user agent to enforce it on.
2020-11-25 14:42:14 [protego] DEBUG: Rule at line 15 without any user agent to enforce it on.
2020-11-25 14:42:14 [protego] DEBUG: Rule at line 17 without any user agent to enforce it on.
2020-11-25 14:42:14 [protego] DEBUG: Rule at line 19 without any user agent to enforce it on.
2020-11-25 14:42:14 [protego] DEBUG: Rule at line 21 without any user agent to enforce it on.
2020-11-25 14:42:14 [protego] DEBUG: Rule at line 23 without any user agent to enforce it on.
2020-11-25 14:42:14 [protego] DEBUG: Rule at line 24 without any user agent to enforce it on.
2020-11-25 14:42:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.shanghairanking.cn/rankings/bcur/2020> (referer: None)
2020-11-25 14:42:16 [scrapy.core.engine] INFO: Closing spider (finished)
2020-11-25 14:42:16 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 472,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 33141,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/404': 1,
 'elapsed_time_seconds': 2.199334,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 11, 25, 6, 42, 16, 642643),
 'log_count/DEBUG': 13,
 'log_count/INFO': 10,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2020, 11, 25, 6, 42, 14, 443309)}
2020-11-25 14:42:16 [scrapy.core.engine] INFO: Spider closed (finished)
2020-11-25 14:43:04 [scrapy.utils.log] INFO: Scrapy 2.3.0 started (bot: ranking)
2020-11-25 14:43:04 [scrapy.utils.log] INFO: Versions: lxml 4.5.2.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.7.6 (tags/v3.7.6:43364a7ae0, Dec 19 2019, 00:42:30) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1h  22 Sep 2020), cryptography 3.1.1, Platform Windows-10-10.0.17763-SP0
2020-11-25 14:43:04 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-11-25 14:43:04 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ranking',
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'ranking.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ranking.spiders']}
2020-11-25 14:43:04 [scrapy.extensions.telnet] INFO: Telnet Password: 8fcab7bb9cd19038
2020-11-25 14:43:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-11-25 14:43:05 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-11-25 14:43:05 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-11-25 14:43:05 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-11-25 14:43:05 [scrapy.core.engine] INFO: Spider opened
2020-11-25 14:43:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-11-25 14:43:05 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-11-25 14:43:05 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.shanghairanking.cn/robots.txt> (referer: None)
2020-11-25 14:43:05 [protego] DEBUG: Rule at line 4 without any user agent to enforce it on.
2020-11-25 14:43:05 [protego] DEBUG: Rule at line 7 without any user agent to enforce it on.
2020-11-25 14:43:05 [protego] DEBUG: Rule at line 9 without any user agent to enforce it on.
2020-11-25 14:43:05 [protego] DEBUG: Rule at line 11 without any user agent to enforce it on.
2020-11-25 14:43:05 [protego] DEBUG: Rule at line 13 without any user agent to enforce it on.
2020-11-25 14:43:05 [protego] DEBUG: Rule at line 15 without any user agent to enforce it on.
2020-11-25 14:43:05 [protego] DEBUG: Rule at line 17 without any user agent to enforce it on.
2020-11-25 14:43:05 [protego] DEBUG: Rule at line 19 without any user agent to enforce it on.
2020-11-25 14:43:05 [protego] DEBUG: Rule at line 21 without any user agent to enforce it on.
2020-11-25 14:43:05 [protego] DEBUG: Rule at line 23 without any user agent to enforce it on.
2020-11-25 14:43:05 [protego] DEBUG: Rule at line 24 without any user agent to enforce it on.
2020-11-25 14:43:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.shanghairanking.cn/rankings/bcur/2020> (referer: None)
2020-11-25 14:43:07 [scrapy.core.engine] INFO: Closing spider (finished)
2020-11-25 14:43:07 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 472,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 33141,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/404': 1,
 'elapsed_time_seconds': 2.064407,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 11, 25, 6, 43, 7, 140221),
 'log_count/DEBUG': 13,
 'log_count/INFO': 10,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2020, 11, 25, 6, 43, 5, 75814)}
2020-11-25 14:43:07 [scrapy.core.engine] INFO: Spider closed (finished)
2020-11-25 14:45:23 [scrapy.utils.log] INFO: Scrapy 2.3.0 started (bot: ranking)
2020-11-25 14:45:23 [scrapy.utils.log] INFO: Versions: lxml 4.5.2.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.7.6 (tags/v3.7.6:43364a7ae0, Dec 19 2019, 00:42:30) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1h  22 Sep 2020), cryptography 3.1.1, Platform Windows-10-10.0.17763-SP0
2020-11-25 14:45:23 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-11-25 14:45:23 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ranking',
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'ranking.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ranking.spiders']}
2020-11-25 14:45:23 [scrapy.extensions.telnet] INFO: Telnet Password: c6fc9fde91730900
2020-11-25 14:45:23 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-11-25 14:45:23 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-11-25 14:45:23 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-11-25 14:45:23 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-11-25 14:45:23 [scrapy.core.engine] INFO: Spider opened
2020-11-25 14:45:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-11-25 14:45:23 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-11-25 14:45:24 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.shanghairanking.cn/robots.txt> (referer: None)
2020-11-25 14:45:24 [protego] DEBUG: Rule at line 4 without any user agent to enforce it on.
2020-11-25 14:45:24 [protego] DEBUG: Rule at line 7 without any user agent to enforce it on.
2020-11-25 14:45:24 [protego] DEBUG: Rule at line 9 without any user agent to enforce it on.
2020-11-25 14:45:24 [protego] DEBUG: Rule at line 11 without any user agent to enforce it on.
2020-11-25 14:45:24 [protego] DEBUG: Rule at line 13 without any user agent to enforce it on.
2020-11-25 14:45:24 [protego] DEBUG: Rule at line 15 without any user agent to enforce it on.
2020-11-25 14:45:24 [protego] DEBUG: Rule at line 17 without any user agent to enforce it on.
2020-11-25 14:45:24 [protego] DEBUG: Rule at line 19 without any user agent to enforce it on.
2020-11-25 14:45:24 [protego] DEBUG: Rule at line 21 without any user agent to enforce it on.
2020-11-25 14:45:24 [protego] DEBUG: Rule at line 23 without any user agent to enforce it on.
2020-11-25 14:45:24 [protego] DEBUG: Rule at line 24 without any user agent to enforce it on.
2020-11-25 14:45:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.shanghairanking.cn/rankings/bcur/2020> (referer: None)
2020-11-25 14:45:26 [scrapy.core.engine] INFO: Closing spider (finished)
2020-11-25 14:45:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 472,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 33141,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/404': 1,
 'elapsed_time_seconds': 2.306619,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 11, 25, 6, 45, 26, 37533),
 'log_count/DEBUG': 13,
 'log_count/INFO': 10,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2020, 11, 25, 6, 45, 23, 730914)}
2020-11-25 14:45:26 [scrapy.core.engine] INFO: Spider closed (finished)
2020-11-25 14:46:10 [scrapy.utils.log] INFO: Scrapy 2.3.0 started (bot: ranking)
2020-11-25 14:46:10 [scrapy.utils.log] INFO: Versions: lxml 4.5.2.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.7.6 (tags/v3.7.6:43364a7ae0, Dec 19 2019, 00:42:30) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1h  22 Sep 2020), cryptography 3.1.1, Platform Windows-10-10.0.17763-SP0
2020-11-25 14:46:10 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-11-25 14:46:10 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ranking',
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'ranking.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ranking.spiders']}
2020-11-25 14:46:10 [scrapy.extensions.telnet] INFO: Telnet Password: 02ebc5a13aad1fbc
2020-11-25 14:46:10 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-11-25 14:46:10 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-11-25 14:46:10 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-11-25 14:46:10 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-11-25 14:46:10 [scrapy.core.engine] INFO: Spider opened
2020-11-25 14:46:10 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-11-25 14:46:10 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-11-25 14:46:11 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.shanghairanking.cn/robots.txt> (referer: None)
2020-11-25 14:46:11 [protego] DEBUG: Rule at line 4 without any user agent to enforce it on.
2020-11-25 14:46:11 [protego] DEBUG: Rule at line 7 without any user agent to enforce it on.
2020-11-25 14:46:11 [protego] DEBUG: Rule at line 9 without any user agent to enforce it on.
2020-11-25 14:46:11 [protego] DEBUG: Rule at line 11 without any user agent to enforce it on.
2020-11-25 14:46:11 [protego] DEBUG: Rule at line 13 without any user agent to enforce it on.
2020-11-25 14:46:11 [protego] DEBUG: Rule at line 15 without any user agent to enforce it on.
2020-11-25 14:46:11 [protego] DEBUG: Rule at line 17 without any user agent to enforce it on.
2020-11-25 14:46:11 [protego] DEBUG: Rule at line 19 without any user agent to enforce it on.
2020-11-25 14:46:11 [protego] DEBUG: Rule at line 21 without any user agent to enforce it on.
2020-11-25 14:46:11 [protego] DEBUG: Rule at line 23 without any user agent to enforce it on.
2020-11-25 14:46:11 [protego] DEBUG: Rule at line 24 without any user agent to enforce it on.
2020-11-25 14:46:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.shanghairanking.cn/rankings/bcur/2020> (referer: None)
2020-11-25 14:46:14 [scrapy.core.engine] INFO: Closing spider (finished)
2020-11-25 14:46:14 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 472,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 33141,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/404': 1,
 'elapsed_time_seconds': 3.975249,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 11, 25, 6, 46, 14, 279995),
 'log_count/DEBUG': 13,
 'log_count/INFO': 10,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2020, 11, 25, 6, 46, 10, 304746)}
2020-11-25 14:46:14 [scrapy.core.engine] INFO: Spider closed (finished)
2020-11-25 14:46:33 [scrapy.utils.log] INFO: Scrapy 2.3.0 started (bot: ranking)
2020-11-25 14:46:33 [scrapy.utils.log] INFO: Versions: lxml 4.5.2.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.7.6 (tags/v3.7.6:43364a7ae0, Dec 19 2019, 00:42:30) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1h  22 Sep 2020), cryptography 3.1.1, Platform Windows-10-10.0.17763-SP0
2020-11-25 14:46:33 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-11-25 14:46:33 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ranking',
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'ranking.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ranking.spiders']}
2020-11-25 14:46:33 [scrapy.extensions.telnet] INFO: Telnet Password: 885dc2cb108f57cf
2020-11-25 14:46:33 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-11-25 14:46:34 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-11-25 14:46:34 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-11-25 14:46:34 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-11-25 14:46:34 [scrapy.core.engine] INFO: Spider opened
2020-11-25 14:46:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-11-25 14:46:34 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-11-25 14:46:34 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.shanghairanking.cn/robots.txt> (referer: None)
2020-11-25 14:46:34 [protego] DEBUG: Rule at line 4 without any user agent to enforce it on.
2020-11-25 14:46:34 [protego] DEBUG: Rule at line 7 without any user agent to enforce it on.
2020-11-25 14:46:34 [protego] DEBUG: Rule at line 9 without any user agent to enforce it on.
2020-11-25 14:46:34 [protego] DEBUG: Rule at line 11 without any user agent to enforce it on.
2020-11-25 14:46:34 [protego] DEBUG: Rule at line 13 without any user agent to enforce it on.
2020-11-25 14:46:34 [protego] DEBUG: Rule at line 15 without any user agent to enforce it on.
2020-11-25 14:46:34 [protego] DEBUG: Rule at line 17 without any user agent to enforce it on.
2020-11-25 14:46:34 [protego] DEBUG: Rule at line 19 without any user agent to enforce it on.
2020-11-25 14:46:34 [protego] DEBUG: Rule at line 21 without any user agent to enforce it on.
2020-11-25 14:46:34 [protego] DEBUG: Rule at line 23 without any user agent to enforce it on.
2020-11-25 14:46:34 [protego] DEBUG: Rule at line 24 without any user agent to enforce it on.
2020-11-25 14:46:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.shanghairanking.cn/rankings/bcur/2020> (referer: None)
2020-11-25 14:46:36 [scrapy.core.engine] INFO: Closing spider (finished)
2020-11-25 14:46:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 472,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 33141,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/404': 1,
 'elapsed_time_seconds': 1.858946,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 11, 25, 6, 46, 36, 53661),
 'log_count/DEBUG': 13,
 'log_count/INFO': 10,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2020, 11, 25, 6, 46, 34, 194715)}
2020-11-25 14:46:36 [scrapy.core.engine] INFO: Spider closed (finished)
2020-11-25 14:49:24 [scrapy.utils.log] INFO: Scrapy 2.3.0 started (bot: ranking)
2020-11-25 14:49:24 [scrapy.utils.log] INFO: Versions: lxml 4.5.2.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.7.6 (tags/v3.7.6:43364a7ae0, Dec 19 2019, 00:42:30) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1h  22 Sep 2020), cryptography 3.1.1, Platform Windows-10-10.0.17763-SP0
2020-11-25 14:49:24 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-11-25 14:49:24 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ranking',
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'ranking.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ranking.spiders']}
2020-11-25 14:49:24 [scrapy.extensions.telnet] INFO: Telnet Password: 4765b75b9c04d509
2020-11-25 14:49:24 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-11-25 14:49:24 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-11-25 14:49:24 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-11-25 14:49:24 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-11-25 14:49:24 [scrapy.core.engine] INFO: Spider opened
2020-11-25 14:49:24 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-11-25 14:49:24 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-11-25 14:49:25 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.shanghairanking.cn/robots.txt> (referer: None)
2020-11-25 14:49:25 [protego] DEBUG: Rule at line 4 without any user agent to enforce it on.
2020-11-25 14:49:25 [protego] DEBUG: Rule at line 7 without any user agent to enforce it on.
2020-11-25 14:49:25 [protego] DEBUG: Rule at line 9 without any user agent to enforce it on.
2020-11-25 14:49:25 [protego] DEBUG: Rule at line 11 without any user agent to enforce it on.
2020-11-25 14:49:25 [protego] DEBUG: Rule at line 13 without any user agent to enforce it on.
2020-11-25 14:49:25 [protego] DEBUG: Rule at line 15 without any user agent to enforce it on.
2020-11-25 14:49:25 [protego] DEBUG: Rule at line 17 without any user agent to enforce it on.
2020-11-25 14:49:25 [protego] DEBUG: Rule at line 19 without any user agent to enforce it on.
2020-11-25 14:49:25 [protego] DEBUG: Rule at line 21 without any user agent to enforce it on.
2020-11-25 14:49:25 [protego] DEBUG: Rule at line 23 without any user agent to enforce it on.
2020-11-25 14:49:25 [protego] DEBUG: Rule at line 24 without any user agent to enforce it on.
2020-11-25 14:49:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.shanghairanking.cn/rankings/bcur/2020> (referer: None)
2020-11-25 14:49:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.shanghairanking.cn/rankings/bcur/2020> (referer: None)
Traceback (most recent call last):
  File "c:\users\user\appdata\local\programs\python\python37\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "C:\Users\user\Documents\Course\爬虫\Web-Crawler\Object6\ranking\ranking\spiders\getRanking.py", line 36, in parse
    self.rangkingSpider(school_url,headers)
AttributeError: 'RankingSpider' object has no attribute 'rangkingSpider'
2020-11-25 14:49:26 [scrapy.core.engine] INFO: Closing spider (finished)
2020-11-25 14:49:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 472,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 33141,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/404': 1,
 'elapsed_time_seconds': 1.729052,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 11, 25, 6, 49, 26, 626171),
 'log_count/DEBUG': 13,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2020, 11, 25, 6, 49, 24, 897119)}
2020-11-25 14:49:26 [scrapy.core.engine] INFO: Spider closed (finished)
2020-11-25 14:50:40 [scrapy.utils.log] INFO: Scrapy 2.3.0 started (bot: ranking)
2020-11-25 14:50:40 [scrapy.utils.log] INFO: Versions: lxml 4.5.2.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.7.6 (tags/v3.7.6:43364a7ae0, Dec 19 2019, 00:42:30) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1h  22 Sep 2020), cryptography 3.1.1, Platform Windows-10-10.0.17763-SP0
2020-11-25 14:50:40 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-11-25 14:50:40 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ranking',
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'ranking.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ranking.spiders']}
2020-11-25 14:50:40 [scrapy.extensions.telnet] INFO: Telnet Password: 50151ad6710cf238
2020-11-25 14:50:40 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-11-25 14:50:41 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-11-25 14:50:41 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-11-25 14:50:41 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-11-25 14:50:41 [scrapy.core.engine] INFO: Spider opened
2020-11-25 14:50:41 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-11-25 14:50:41 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-11-25 14:50:41 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.shanghairanking.cn/robots.txt> (referer: None)
2020-11-25 14:50:41 [protego] DEBUG: Rule at line 4 without any user agent to enforce it on.
2020-11-25 14:50:41 [protego] DEBUG: Rule at line 7 without any user agent to enforce it on.
2020-11-25 14:50:41 [protego] DEBUG: Rule at line 9 without any user agent to enforce it on.
2020-11-25 14:50:41 [protego] DEBUG: Rule at line 11 without any user agent to enforce it on.
2020-11-25 14:50:41 [protego] DEBUG: Rule at line 13 without any user agent to enforce it on.
2020-11-25 14:50:41 [protego] DEBUG: Rule at line 15 without any user agent to enforce it on.
2020-11-25 14:50:41 [protego] DEBUG: Rule at line 17 without any user agent to enforce it on.
2020-11-25 14:50:41 [protego] DEBUG: Rule at line 19 without any user agent to enforce it on.
2020-11-25 14:50:41 [protego] DEBUG: Rule at line 21 without any user agent to enforce it on.
2020-11-25 14:50:41 [protego] DEBUG: Rule at line 23 without any user agent to enforce it on.
2020-11-25 14:50:41 [protego] DEBUG: Rule at line 24 without any user agent to enforce it on.
2020-11-25 14:50:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.shanghairanking.cn/rankings/bcur/2020> (referer: None)
2020-11-25 14:50:58 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2020-11-25 14:51:00 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
2020-11-25 14:52:54 [scrapy.utils.log] INFO: Scrapy 2.3.0 started (bot: ranking)
2020-11-25 14:52:54 [scrapy.utils.log] INFO: Versions: lxml 4.5.2.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.7.6 (tags/v3.7.6:43364a7ae0, Dec 19 2019, 00:42:30) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1h  22 Sep 2020), cryptography 3.1.1, Platform Windows-10-10.0.17763-SP0
2020-11-25 14:52:54 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-11-25 14:52:54 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ranking',
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'ranking.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ranking.spiders']}
2020-11-25 14:52:54 [scrapy.extensions.telnet] INFO: Telnet Password: 646b31791df6208b
2020-11-25 14:52:54 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-11-25 14:52:54 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-11-25 14:52:54 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-11-25 14:52:54 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-11-25 14:52:54 [scrapy.core.engine] INFO: Spider opened
2020-11-25 14:52:54 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-11-25 14:52:54 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-11-25 14:52:55 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.shanghairanking.cn/robots.txt> (referer: None)
2020-11-25 14:52:55 [protego] DEBUG: Rule at line 4 without any user agent to enforce it on.
2020-11-25 14:52:55 [protego] DEBUG: Rule at line 7 without any user agent to enforce it on.
2020-11-25 14:52:55 [protego] DEBUG: Rule at line 9 without any user agent to enforce it on.
2020-11-25 14:52:55 [protego] DEBUG: Rule at line 11 without any user agent to enforce it on.
2020-11-25 14:52:55 [protego] DEBUG: Rule at line 13 without any user agent to enforce it on.
2020-11-25 14:52:55 [protego] DEBUG: Rule at line 15 without any user agent to enforce it on.
2020-11-25 14:52:55 [protego] DEBUG: Rule at line 17 without any user agent to enforce it on.
2020-11-25 14:52:55 [protego] DEBUG: Rule at line 19 without any user agent to enforce it on.
2020-11-25 14:52:55 [protego] DEBUG: Rule at line 21 without any user agent to enforce it on.
2020-11-25 14:52:55 [protego] DEBUG: Rule at line 23 without any user agent to enforce it on.
2020-11-25 14:52:55 [protego] DEBUG: Rule at line 24 without any user agent to enforce it on.
2020-11-25 14:52:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.shanghairanking.cn/rankings/bcur/2020> (referer: None)
2020-11-25 14:52:56 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2020-11-25 14:55:38 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
2020-11-25 15:04:45 [scrapy.utils.log] INFO: Scrapy 2.3.0 started (bot: ranking)
2020-11-25 15:04:45 [scrapy.utils.log] INFO: Versions: lxml 4.5.2.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.7.6 (tags/v3.7.6:43364a7ae0, Dec 19 2019, 00:42:30) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1h  22 Sep 2020), cryptography 3.1.1, Platform Windows-10-10.0.17763-SP0
2020-11-25 15:04:45 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-11-25 15:04:45 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ranking',
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'ranking.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ranking.spiders']}
2020-11-25 15:04:45 [scrapy.extensions.telnet] INFO: Telnet Password: fbd3147d77441de5
2020-11-25 15:04:45 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-11-25 15:04:46 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-11-25 15:04:46 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-11-25 15:04:46 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-11-25 15:04:46 [scrapy.core.engine] INFO: Spider opened
2020-11-25 15:04:46 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-11-25 15:04:46 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-11-25 15:04:46 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.shanghairanking.cn/robots.txt> (referer: None)
2020-11-25 15:04:46 [protego] DEBUG: Rule at line 4 without any user agent to enforce it on.
2020-11-25 15:04:46 [protego] DEBUG: Rule at line 7 without any user agent to enforce it on.
2020-11-25 15:04:46 [protego] DEBUG: Rule at line 9 without any user agent to enforce it on.
2020-11-25 15:04:46 [protego] DEBUG: Rule at line 11 without any user agent to enforce it on.
2020-11-25 15:04:46 [protego] DEBUG: Rule at line 13 without any user agent to enforce it on.
2020-11-25 15:04:46 [protego] DEBUG: Rule at line 15 without any user agent to enforce it on.
2020-11-25 15:04:46 [protego] DEBUG: Rule at line 17 without any user agent to enforce it on.
2020-11-25 15:04:46 [protego] DEBUG: Rule at line 19 without any user agent to enforce it on.
2020-11-25 15:04:46 [protego] DEBUG: Rule at line 21 without any user agent to enforce it on.
2020-11-25 15:04:46 [protego] DEBUG: Rule at line 23 without any user agent to enforce it on.
2020-11-25 15:04:46 [protego] DEBUG: Rule at line 24 without any user agent to enforce it on.
2020-11-25 15:04:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.shanghairanking.cn/rankings/bcur/2020> (referer: None)
2020-11-25 15:05:27 [scrapy.core.engine] INFO: Closing spider (finished)
2020-11-25 15:05:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 472,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 33141,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/404': 1,
 'elapsed_time_seconds': 41.847159,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 11, 25, 7, 5, 28, 90019),
 'log_count/DEBUG': 13,
 'log_count/INFO': 10,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2020, 11, 25, 7, 4, 46, 242860)}
2020-11-25 15:05:28 [scrapy.core.engine] INFO: Spider closed (finished)
2020-11-25 15:07:42 [scrapy.utils.log] INFO: Scrapy 2.3.0 started (bot: ranking)
2020-11-25 15:07:42 [scrapy.utils.log] INFO: Versions: lxml 4.5.2.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.7.6 (tags/v3.7.6:43364a7ae0, Dec 19 2019, 00:42:30) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1h  22 Sep 2020), cryptography 3.1.1, Platform Windows-10-10.0.17763-SP0
2020-11-25 15:07:42 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-11-25 15:07:42 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ranking',
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'ranking.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ranking.spiders']}
2020-11-25 15:07:42 [scrapy.extensions.telnet] INFO: Telnet Password: e26ef116a0ce9f34
2020-11-25 15:07:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-11-25 15:07:42 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-11-25 15:07:42 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-11-25 15:07:42 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-11-25 15:07:42 [scrapy.core.engine] INFO: Spider opened
2020-11-25 15:07:42 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-11-25 15:07:42 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-11-25 15:07:42 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.shanghairanking.cn/robots.txt> (referer: None)
2020-11-25 15:07:42 [protego] DEBUG: Rule at line 4 without any user agent to enforce it on.
2020-11-25 15:07:42 [protego] DEBUG: Rule at line 7 without any user agent to enforce it on.
2020-11-25 15:07:42 [protego] DEBUG: Rule at line 9 without any user agent to enforce it on.
2020-11-25 15:07:42 [protego] DEBUG: Rule at line 11 without any user agent to enforce it on.
2020-11-25 15:07:42 [protego] DEBUG: Rule at line 13 without any user agent to enforce it on.
2020-11-25 15:07:42 [protego] DEBUG: Rule at line 15 without any user agent to enforce it on.
2020-11-25 15:07:42 [protego] DEBUG: Rule at line 17 without any user agent to enforce it on.
2020-11-25 15:07:42 [protego] DEBUG: Rule at line 19 without any user agent to enforce it on.
2020-11-25 15:07:42 [protego] DEBUG: Rule at line 21 without any user agent to enforce it on.
2020-11-25 15:07:42 [protego] DEBUG: Rule at line 23 without any user agent to enforce it on.
2020-11-25 15:07:42 [protego] DEBUG: Rule at line 24 without any user agent to enforce it on.
2020-11-25 15:07:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.shanghairanking.cn/rankings/bcur/2020> (referer: None)
2020-11-25 15:08:18 [scrapy.core.engine] INFO: Closing spider (finished)
2020-11-25 15:08:18 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 472,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 33141,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/404': 1,
 'elapsed_time_seconds': 35.736618,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 11, 25, 7, 8, 18, 395620),
 'log_count/DEBUG': 13,
 'log_count/INFO': 10,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2020, 11, 25, 7, 7, 42, 659002)}
2020-11-25 15:08:18 [scrapy.core.engine] INFO: Spider closed (finished)
2020-11-25 15:08:41 [scrapy.utils.log] INFO: Scrapy 2.3.0 started (bot: ranking)
2020-11-25 15:08:41 [scrapy.utils.log] INFO: Versions: lxml 4.5.2.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.7.6 (tags/v3.7.6:43364a7ae0, Dec 19 2019, 00:42:30) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1h  22 Sep 2020), cryptography 3.1.1, Platform Windows-10-10.0.17763-SP0
2020-11-25 15:08:41 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-11-25 15:08:41 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ranking',
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'ranking.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ranking.spiders']}
2020-11-25 15:08:41 [scrapy.extensions.telnet] INFO: Telnet Password: 3424d1871c04b86b
2020-11-25 15:08:41 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-11-25 15:08:41 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-11-25 15:08:41 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-11-25 15:08:41 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-11-25 15:08:41 [scrapy.core.engine] INFO: Spider opened
2020-11-25 15:08:41 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-11-25 15:08:41 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-11-25 15:08:42 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.shanghairanking.cn/robots.txt> (referer: None)
2020-11-25 15:08:42 [protego] DEBUG: Rule at line 4 without any user agent to enforce it on.
2020-11-25 15:08:42 [protego] DEBUG: Rule at line 7 without any user agent to enforce it on.
2020-11-25 15:08:42 [protego] DEBUG: Rule at line 9 without any user agent to enforce it on.
2020-11-25 15:08:42 [protego] DEBUG: Rule at line 11 without any user agent to enforce it on.
2020-11-25 15:08:42 [protego] DEBUG: Rule at line 13 without any user agent to enforce it on.
2020-11-25 15:08:42 [protego] DEBUG: Rule at line 15 without any user agent to enforce it on.
2020-11-25 15:08:42 [protego] DEBUG: Rule at line 17 without any user agent to enforce it on.
2020-11-25 15:08:42 [protego] DEBUG: Rule at line 19 without any user agent to enforce it on.
2020-11-25 15:08:42 [protego] DEBUG: Rule at line 21 without any user agent to enforce it on.
2020-11-25 15:08:42 [protego] DEBUG: Rule at line 23 without any user agent to enforce it on.
2020-11-25 15:08:42 [protego] DEBUG: Rule at line 24 without any user agent to enforce it on.
2020-11-25 15:08:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.shanghairanking.cn/rankings/bcur/2020> (referer: None)
2020-11-25 15:08:55 [scrapy.core.engine] INFO: Closing spider (finished)
2020-11-25 15:08:55 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 472,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 33141,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/404': 1,
 'elapsed_time_seconds': 13.347635,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 11, 25, 7, 8, 55, 137155),
 'log_count/DEBUG': 13,
 'log_count/INFO': 10,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2020, 11, 25, 7, 8, 41, 789520)}
2020-11-25 15:08:55 [scrapy.core.engine] INFO: Spider closed (finished)
2020-11-25 15:10:43 [scrapy.utils.log] INFO: Scrapy 2.3.0 started (bot: ranking)
2020-11-25 15:10:43 [scrapy.utils.log] INFO: Versions: lxml 4.5.2.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.7.6 (tags/v3.7.6:43364a7ae0, Dec 19 2019, 00:42:30) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1h  22 Sep 2020), cryptography 3.1.1, Platform Windows-10-10.0.17763-SP0
2020-11-25 15:10:43 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-11-25 15:10:43 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ranking',
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'ranking.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ranking.spiders']}
2020-11-25 15:10:43 [scrapy.extensions.telnet] INFO: Telnet Password: cb642c3ae2ab38f7
2020-11-25 15:10:43 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-11-25 15:10:43 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-11-25 15:10:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-11-25 15:10:43 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-11-25 15:10:43 [scrapy.core.engine] INFO: Spider opened
2020-11-25 15:10:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-11-25 15:10:43 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-11-25 15:10:44 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.shanghairanking.cn/robots.txt> (referer: None)
2020-11-25 15:10:44 [protego] DEBUG: Rule at line 4 without any user agent to enforce it on.
2020-11-25 15:10:44 [protego] DEBUG: Rule at line 7 without any user agent to enforce it on.
2020-11-25 15:10:44 [protego] DEBUG: Rule at line 9 without any user agent to enforce it on.
2020-11-25 15:10:44 [protego] DEBUG: Rule at line 11 without any user agent to enforce it on.
2020-11-25 15:10:44 [protego] DEBUG: Rule at line 13 without any user agent to enforce it on.
2020-11-25 15:10:44 [protego] DEBUG: Rule at line 15 without any user agent to enforce it on.
2020-11-25 15:10:44 [protego] DEBUG: Rule at line 17 without any user agent to enforce it on.
2020-11-25 15:10:44 [protego] DEBUG: Rule at line 19 without any user agent to enforce it on.
2020-11-25 15:10:44 [protego] DEBUG: Rule at line 21 without any user agent to enforce it on.
2020-11-25 15:10:44 [protego] DEBUG: Rule at line 23 without any user agent to enforce it on.
2020-11-25 15:10:44 [protego] DEBUG: Rule at line 24 without any user agent to enforce it on.
2020-11-25 15:10:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.shanghairanking.cn/rankings/bcur/2020> (referer: None)
2020-11-25 15:10:59 [scrapy.core.engine] INFO: Closing spider (finished)
2020-11-25 15:10:59 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 472,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 33141,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/404': 1,
 'elapsed_time_seconds': 15.879349,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 11, 25, 7, 10, 59, 689425),
 'log_count/DEBUG': 13,
 'log_count/INFO': 10,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2020, 11, 25, 7, 10, 43, 810076)}
2020-11-25 15:10:59 [scrapy.core.engine] INFO: Spider closed (finished)
2020-11-25 15:19:39 [scrapy.utils.log] INFO: Scrapy 2.3.0 started (bot: ranking)
2020-11-25 15:19:39 [scrapy.utils.log] INFO: Versions: lxml 4.5.2.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.7.6 (tags/v3.7.6:43364a7ae0, Dec 19 2019, 00:42:30) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1h  22 Sep 2020), cryptography 3.1.1, Platform Windows-10-10.0.17763-SP0
2020-11-25 15:19:39 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-11-25 15:19:39 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ranking',
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'ranking.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ranking.spiders']}
2020-11-25 15:19:39 [scrapy.extensions.telnet] INFO: Telnet Password: 2a5393eb870e1dae
2020-11-25 15:19:39 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-11-25 15:19:40 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-11-25 15:19:40 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-11-25 15:19:40 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-11-25 15:19:40 [scrapy.core.engine] INFO: Spider opened
2020-11-25 15:19:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-11-25 15:19:40 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-11-25 15:19:40 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.shanghairanking.cn/robots.txt> (referer: None)
2020-11-25 15:19:40 [protego] DEBUG: Rule at line 4 without any user agent to enforce it on.
2020-11-25 15:19:40 [protego] DEBUG: Rule at line 7 without any user agent to enforce it on.
2020-11-25 15:19:40 [protego] DEBUG: Rule at line 9 without any user agent to enforce it on.
2020-11-25 15:19:40 [protego] DEBUG: Rule at line 11 without any user agent to enforce it on.
2020-11-25 15:19:40 [protego] DEBUG: Rule at line 13 without any user agent to enforce it on.
2020-11-25 15:19:40 [protego] DEBUG: Rule at line 15 without any user agent to enforce it on.
2020-11-25 15:19:40 [protego] DEBUG: Rule at line 17 without any user agent to enforce it on.
2020-11-25 15:19:40 [protego] DEBUG: Rule at line 19 without any user agent to enforce it on.
2020-11-25 15:19:40 [protego] DEBUG: Rule at line 21 without any user agent to enforce it on.
2020-11-25 15:19:40 [protego] DEBUG: Rule at line 23 without any user agent to enforce it on.
2020-11-25 15:19:40 [protego] DEBUG: Rule at line 24 without any user agent to enforce it on.
2020-11-25 15:19:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.shanghairanking.cn/rankings/bcur/2020> (referer: None)
2020-11-25 15:20:03 [scrapy.core.engine] INFO: Closing spider (finished)
2020-11-25 15:20:03 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 472,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 33141,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/404': 1,
 'elapsed_time_seconds': 23.352339,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 11, 25, 7, 20, 3, 402150),
 'log_count/DEBUG': 13,
 'log_count/INFO': 10,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2020, 11, 25, 7, 19, 40, 49811)}
2020-11-25 15:20:03 [scrapy.core.engine] INFO: Spider closed (finished)
2020-11-25 15:27:28 [scrapy.utils.log] INFO: Scrapy 2.3.0 started (bot: ranking)
2020-11-25 15:27:28 [scrapy.utils.log] INFO: Versions: lxml 4.5.2.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 20.3.0, Python 3.7.6 (tags/v3.7.6:43364a7ae0, Dec 19 2019, 00:42:30) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1h  22 Sep 2020), cryptography 3.1.1, Platform Windows-10-10.0.17763-SP0
2020-11-25 15:27:28 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2020-11-25 15:27:28 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'ranking',
 'LOG_FILE': 'all.log',
 'NEWSPIDER_MODULE': 'ranking.spiders',
 'ROBOTSTXT_OBEY': True,
 'SPIDER_LOADER_WARN_ONLY': True,
 'SPIDER_MODULES': ['ranking.spiders']}
2020-11-25 15:27:28 [scrapy.extensions.telnet] INFO: Telnet Password: 6c42756a5ec4ac8a
2020-11-25 15:27:28 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2020-11-25 15:27:29 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-11-25 15:27:29 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-11-25 15:27:29 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2020-11-25 15:27:29 [scrapy.core.engine] INFO: Spider opened
2020-11-25 15:27:29 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-11-25 15:27:29 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2020-11-25 15:27:29 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://www.shanghairanking.cn/robots.txt> (referer: None)
2020-11-25 15:27:29 [protego] DEBUG: Rule at line 4 without any user agent to enforce it on.
2020-11-25 15:27:29 [protego] DEBUG: Rule at line 7 without any user agent to enforce it on.
2020-11-25 15:27:29 [protego] DEBUG: Rule at line 9 without any user agent to enforce it on.
2020-11-25 15:27:29 [protego] DEBUG: Rule at line 11 without any user agent to enforce it on.
2020-11-25 15:27:29 [protego] DEBUG: Rule at line 13 without any user agent to enforce it on.
2020-11-25 15:27:29 [protego] DEBUG: Rule at line 15 without any user agent to enforce it on.
2020-11-25 15:27:29 [protego] DEBUG: Rule at line 17 without any user agent to enforce it on.
2020-11-25 15:27:29 [protego] DEBUG: Rule at line 19 without any user agent to enforce it on.
2020-11-25 15:27:29 [protego] DEBUG: Rule at line 21 without any user agent to enforce it on.
2020-11-25 15:27:29 [protego] DEBUG: Rule at line 23 without any user agent to enforce it on.
2020-11-25 15:27:29 [protego] DEBUG: Rule at line 24 without any user agent to enforce it on.
2020-11-25 15:27:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.shanghairanking.cn/rankings/bcur/2020> (referer: None)
2020-11-25 15:27:48 [scrapy.core.engine] INFO: Closing spider (finished)
2020-11-25 15:27:48 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 472,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 33141,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/404': 1,
 'elapsed_time_seconds': 18.995842,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2020, 11, 25, 7, 27, 48, 6763),
 'log_count/DEBUG': 13,
 'log_count/INFO': 10,
 'response_received_count': 2,
 'robotstxt/request_count': 1,
 'robotstxt/response_count': 1,
 'robotstxt/response_status_count/404': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2020, 11, 25, 7, 27, 29, 10921)}
2020-11-25 15:27:48 [scrapy.core.engine] INFO: Spider closed (finished)
